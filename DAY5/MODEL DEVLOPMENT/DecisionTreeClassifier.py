# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kC67Jd2mPKDepKbPbmfreA-zcfiPHI03
"""

# 2. Import libraries
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

from google.colab import files
uploaded = files.upload()  # Choose your events_cleaned_label_encoded.csv
file_path = list(uploaded.keys())[0]

df = pd.read_csv(file_path)
print("âœ… Data loaded:", df.shape)
print(df.head())

# 4. Convert date columns
date_cols = ["date_initiated_by_firm", "date_updated", "date_terminated"]
for col in date_cols:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors="coerce")

df = df.sort_values(by=["device_id", "date_initiated_by_firm"])

features = []
for device, group in df.groupby("device_id"):
    group = group.sort_values("date_initiated_by_firm")

    # Failure counts
    total_recalls = (group["action"] == "Recall").sum() if "action" in df.columns else 0

    # Average recall duration
    if "date_terminated" in df.columns and "date_initiated_by_firm" in df.columns:
        durations = (group["date_terminated"] - group["date_initiated_by_firm"]).dt.days.dropna()
        avg_duration = durations.mean() if not durations.empty else 0
    else:
        avg_duration = 0

    # Time between recalls
    gaps = group["date_initiated_by_firm"].diff().dt.days.dropna()
    avg_gap = gaps.mean() if not gaps.empty else 0

    # Severity distribution
    if "action_classification" in df.columns:
        class_counts = group["action_classification"].value_counts(normalize=True).to_dict()
        class1_pct = class_counts.get("Class I", 0)
        class2_pct = class_counts.get("Class II", 0)
        class3_pct = class_counts.get("Class III", 0)
    else:
        class1_pct = class2_pct = class3_pct = 0

    # Recency (days since last recall)
    last_event = group["date_initiated_by_firm"].max()
    days_since_last = (datetime.now() - last_event).days if pd.notna(last_event) else np.nan

    # Target: Did the device fail again within 180 days after last recall?
    next_event = group["date_initiated_by_firm"].shift(-1)
    if pd.notna(next_event.iloc[-1]) and pd.notna(last_event):
        target = 1 if (next_event.iloc[-1] - last_event).days <= 180 else 0
    else:
        target = 0

    features.append({
        "device_id": device,
        "total_recalls": total_recalls,
        "avg_duration": avg_duration,
        "avg_gap": avg_gap,
        "class1_pct": class1_pct,
        "class2_pct": class2_pct,
        "class3_pct": class3_pct,
        "days_since_last": days_since_last,
        "target_failure_180d": target
    })

features_df = pd.DataFrame(features)
print("âœ… Features created:", features_df.shape)
print(features_df.head())

# 6. Train/Test Split
X = features_df.drop(columns=["device_id", "target_failure_180d"])
y = features_df["target_failure_180d"]
X = X.fillna(0)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 7. Train Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 8. Evaluate
y_pred = model.predict(X_test)
print("\nðŸ“Š Classification Report")
print(classification_report(y_test, y_pred))
print("\nðŸ”¹ Confusion Matrix")
print(confusion_matrix(y_test, y_pred))