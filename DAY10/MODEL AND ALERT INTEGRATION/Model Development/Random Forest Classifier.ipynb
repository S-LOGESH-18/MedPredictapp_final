{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -- coding: utf-8 --\n",
        "# ðŸš€ Faulty Device Severity Prediction (RandomForest + Fixed Encoders + Export)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# --------------------------\n",
        "# STEP 1: Load Data\n",
        "# --------------------------\n",
        "df = pd.read_csv(\"events_cleaned_label_encoded.csv\", encoding=\"ISO-8859-1\", low_memory=False)\n",
        "\n",
        "# --------------------------\n",
        "# STEP 2: Preprocessing Dates\n",
        "# --------------------------\n",
        "df[\"date_initiated_by_firm\"] = pd.to_datetime(df[\"date_initiated_by_firm\"], errors=\"coerce\", dayfirst=True)\n",
        "df[\"date_terminated\"] = pd.to_datetime(df[\"date_terminated\"], errors=\"coerce\", dayfirst=True)\n",
        "df[\"date_updated\"] = pd.to_datetime(df[\"date_updated\"], errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "# --------------------------\n",
        "# STEP 3: Recall Duration Logic\n",
        "# --------------------------\n",
        "df[\"recall_duration_days\"] = np.nan\n",
        "\n",
        "terminated_mask = df[\"status\"].str.lower() == \"terminated\"\n",
        "df.loc[terminated_mask, \"recall_duration_days\"] = (\n",
        "    df.loc[terminated_mask, \"date_terminated\"] - df.loc[terminated_mask, \"date_initiated_by_firm\"]\n",
        ").dt.days\n",
        "\n",
        "ongoing_mask = df[\"status\"].str.lower() == \"ongoing\"\n",
        "df.loc[ongoing_mask, \"recall_duration_days\"] = (\n",
        "    df.loc[ongoing_mask, \"date_updated\"] - df.loc[ongoing_mask, \"date_initiated_by_firm\"]\n",
        ").dt.days\n",
        "\n",
        "df[\"recall_duration_days\"] = df[\"recall_duration_days\"].fillna(df[\"recall_duration_days\"].median())\n",
        "\n",
        "# --------------------------\n",
        "# STEP 4: Target Label\n",
        "# --------------------------\n",
        "df[\"label\"] = np.where(df[\"recall_duration_days\"] <= 50, 1, 0)\n",
        "print(\"Label distribution:\\n\", df[\"label\"].value_counts())\n",
        "\n",
        "# --------------------------\n",
        "# STEP 5: Feature Selection\n",
        "# --------------------------\n",
        "exclude_cols = [\"device_id\", \"date_initiated_by_firm\", \"date_terminated\", \"date_updated\",\n",
        "                \"recall_duration_days\", \"label\"]\n",
        "\n",
        "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
        "print(\"Using features:\", feature_cols)\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[\"label\"]\n",
        "\n",
        "# --------------------------\n",
        "# STEP 6: Encode Categoricals (Save Encoders)\n",
        "# --------------------------\n",
        "encoders = {}\n",
        "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "    encoders[col] = le  # save encoder for inference\n",
        "\n",
        "# --------------------------\n",
        "# STEP 7: Train/Test Split\n",
        "# --------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# STEP 8: Train Random Forest\n",
        "# --------------------------\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --------------------------\n",
        "# STEP 9: Evaluate\n",
        "# --------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# --------------------------\n",
        "# STEP 10: Save as Single Artifact\n",
        "# --------------------------\n",
        "artifact = {\n",
        "    \"model\": model,\n",
        "    \"feature_cols\": feature_cols,\n",
        "    \"encoders\": encoders\n",
        "}\n",
        "\n",
        "# joblib.dump(artifact, \"device_failure_pipeline.joblib\", compress=3)\n",
        "# print(\"âœ… Single pipeline joblib saved successfully.\")\n",
        "\n",
        "# --------------------------\n",
        "# STEP 11: Predict Function\n",
        "# --------------------------\n",
        "def predict_device_failure(device_id):\n",
        "    device_row = df[df[\"device_id\"] == device_id].copy()\n",
        "    if device_row.empty:\n",
        "        return {\"error\": f\"Device ID {device_id} not found\"}\n",
        "\n",
        "    X_new = device_row[artifact[\"feature_cols\"]].copy()\n",
        "\n",
        "    # Apply SAME encoders\n",
        "    for col, le in artifact[\"encoders\"].items():\n",
        "        if col in X_new:\n",
        "            X_new[col] = le.transform(X_new[col].astype(str))\n",
        "\n",
        "    pred_class = artifact[\"model\"].predict(X_new)[0]\n",
        "    pred_prob = artifact[\"model\"].predict_proba(X_new)[0][1]\n",
        "\n",
        "    return {\n",
        "        \"device_id\": int(device_id),\n",
        "        \"failure_prediction\": int(pred_class),\n",
        "        \"risk_percentage\": round(float(pred_prob) * 100, 2),\n",
        "        \"within_50_days\": \"Yes\" if pred_class == 1 else \"No\"\n",
        "    }\n",
        "\n",
        "# --------------------------\n",
        "# STEP 12: Example Run (20 Random Devices)\n",
        "# --------------------------\n",
        "\n",
        "print(\"\\nðŸ” Predictions for given Device:\\n\")\n",
        "print(predict_device_failure(19717))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxmq8ifPNNL1",
        "outputId": "ac87edb2-c9ec-453a-b780-a938d69fd471"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution:\n",
            " label\n",
            "0    57521\n",
            "1    42479\n",
            "Name: count, dtype: int64\n",
            "Using features: ['id', 'action', 'action_classification', 'action_summary', 'reason', 'manufacturer_id', 'type', 'date_posted', 'status']\n",
            "âœ… Accuracy: 0.69865\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.84      0.76     11504\n",
            "           1       0.70      0.51      0.59      8496\n",
            "\n",
            "    accuracy                           0.70     20000\n",
            "   macro avg       0.70      0.67      0.68     20000\n",
            "weighted avg       0.70      0.70      0.69     20000\n",
            "\n",
            "\n",
            "ðŸ” Predictions for given Device:\n",
            "\n",
            "{'device_id': 19717, 'failure_prediction': 0, 'risk_percentage': 9.33, 'within_50_days': 'No'}\n"
          ]
        }
      ]
    }
  ]
}